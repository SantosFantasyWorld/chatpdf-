# 复现流程（设计过程）

## 配置环境

打开vscode编译器后，创建一个app.py的文件

再打开terminal，最好选择git bash终端， 输入以下内容用于配置编译环境

~~~
pip install langchain pypdf2 python-dotenv streamlit
~~~

Streamlit是一个用于快速构建数据应用的开源Python库。它可以帮助开发者轻松地创建交互式Web应用，无需具备前端开发经验。Streamlit的设计理念是让数据科学家和工程师能够专注于数据分析和模型构建，而不是在界面设计和Web开发上花费大量时间。

langchain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。

PyPDF2是一个用于处理PDF文件的纯Python库。它可以用于从PDF文档中提取信息、分割、合并和裁剪页面以及向PDF文档中添加内容和注释。PyPDF2不直接处理文本或图形渲染，它主要关注与PDF文件结构和内容的操作

再创建一个.env文件用来存储参数

~~~
OPENAI_API_KEY = "请输入你的API_KEY"
~~~

注意，这个变量只能命名为'OPENAI_API_KEY',这是因为我们是引用langchain的外部源，它只认这个变量名

再创建一个gitignore文件，再从[gitignore/Python.gitignore at main · github/gitignore](https://github.com/github/gitignore/blob/main/Python.gitignore)里面把所有文件copy进来就行，这个没什么好讲的

再用Python在app.py上编写的一个简单的Streamlit应用，用于在Web页面上创建一个PDF文件上传功能

~~~
from dotenv import load_dotenv
import streamlit as st

def main():
    load_dotenv()
    st.set_page_config(page_title="Ask your PDF")
    st.title("Ask your PDF")
    
if __name__ == "__main__":
    main()
~~~

## 具体复现

### 流程图

![Ask a Book Questions Workflow](http://bennycheung.github.io/images/ask-a-book-questions-with-langchain-openai/Ask_Book_Questions_Workflow.jpg)

1. 提取文本
2. 分割文本
3. Embedding 过程并建立知识库
4. 根据输入的embedding排序相似程度

### 提取文本

对之前代码进行进一步精细化处理，使其能够在上传PDF文件后提取其文本内容。

~~~
from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader

def main():
    load_dotenv()
    st.set_page_config(page_title="Ask your PDF")
    st.title("Ask your PDF")
    pdf = st.file_uploader("Upload your PDF", type="pdf")
    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
~~~

以下是代码的详细解释：

1. 导入库：

   - `from dotenv import load_dotenv`：从`dotenv`库中导入`load_dotenv`函数，用于从`.env`文件中加载环境变量。
   - `import streamlit as st`：导入`streamlit`库并将其别名设置为`st`，以便更方便地使用。
   - `from PyPDF2 import PdfReader`：导入`PyPDF2`库中导入`pdfreader`函数，以便更方便地读取pdf文件。

2. 定义`main`函数：

   - `load_dotenv()`：调用`load_dotenv`函数，加载环境变量。

   - `st.set_page_config(page_title="Ask your PDF")`：使用`st.set_page_config`函数设置Web页面的标题为“Ask your PDF”。

   - `st.title("Ask your PDF")`：使用`st.title`函数在Web页面上显示标题“Ask your PDF”。

   - `pdf = st.file_uploader("Upload your PDF", type="pdf")`：使用`st.file_uploader`函数在Web页面上创建一个文件上传器，允许用户上传PDF文件。文件上传器的提示文本为“Upload your PDF”，并限制文件类型为PDF。

   - `if pdf is not None:`：使用`if`语句检查用户是否已上传PDF文件。如果用户已上传文件（即`pdf`不是`None`），则执行以下代码块：

     - `pdf_reader = PdfReader(pdf)`：创建一个`PdfReader`实例来读取用户上传的PDF文件。

     - `text = ""`：初始化一个空字符串`text`，用于存储从PDF文件中提取的文本。

     - ```
       for page in pdf_reader.pages:
       ```

       ：遍历PDF文件的每一页，执行以下代码块：

       - `text += page.extract_text()`：使用`page.extract_text()`方法从当前页面提取文本，并将其添加到`text`变量中。

   ### 分割文本

   然后将提取的文本分割成多个较小的文本块，接上文，代码如下

   ~~~
   from dotenv import load_dotenv
   import streamlit as st
   from PyPDF2 import PdfReader
   from langchain.text_splitter import CharacterTextSplitter
   
   def main():
       load_dotenv()
       st.set_page_config(page_title="Ask your PDF")
       st.title("Ask your PDF")
   
       pdf = st.file_uploader("Upload your PDF", type="pdf")
   
       if pdf is not None:
           pdf_reader = PdfReader(pdf)
           text = ""
           for page in pdf_reader.pages:
               text += page.extract_text()
           # split into chunks
           text_splitter = CharacterTextSplitter(
               separator="\n",
               chunk_size=1000,
               chunk_overlap=200,
               length_function=len,
           )
           chunks = text_splitter.split_text(text)
   ~~~

   以下是代码的详细解释：

   `from langchain.text_splitter import CharacterTextSplitter`：从`langchain.text_splitter`模块中导入`CharacterTextSplitter`类。

   - `text_splitter = CharacterTextSplitter(...)`：创建一个`CharacterTextSplitter`实例，用于将提取的文本分割成多个较小的文本块。以下是参数的解释：
     - `separator="\n"`：设置文本分割符为换行符。
     - `chunk_size=1000`：设置每个文本块的最大长度为1000个字符。
     - `chunk_overlap=200`：设置相邻文本块之间的重叠长度为200个字符。
     - `length_function=len`：设置计算文本长度的函数为内置的`len`函数。
   - `chunks = text_splitter.split_text(text)`：方法将提取到的文本`text`分割成多个较小的文本块，并将结果存储在`chunks`变量中。

### Embedding 过程并建立知识库

使用OpenAIEmbeddings为这些文本块创建嵌入向量，并将它们存储在一个FAISS向量存储（知识库）中，接上文，代码如下

~~~
from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS

def main():
    load_dotenv()
    st.set_page_config(page_title="Ask your PDF")
    st.title("Ask your PDF")

    pdf = st.file_uploader("Upload your PDF", type="pdf")

    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()

        # split into chunks
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )

        chunks = text_splitter.split_text(text)

        # create embeddings
        embeddings = OpenAIEmbeddings()
        knowledge_base = FAISS.from_texts(chunks, embeddings)
~~~

- `from langchain.embeddings.openai import OpenAIEmbeddings`：从`langchain.embeddings.openai`模块中导入`OpenAIEmbeddings`类
- `from langchain.vectorstores import FAISS`：从`langchain.vectorstores`模块中导入`FAISS`类
- `embeddings = OpenAIEmbeddings()`：创建一个`OpenAIEmbeddings`实例，用于为文本生成嵌入向量。
- `knowledge_base = FAISS.from_texts(chunks, embeddings)`：调用`FAISS.from_texts`方法，为`chunks`中的每个文本块生成嵌入向量（使用`embeddings`实例），并将这些向量存储在一个FAISS向量存储中。

### 根据输入的embedding排序相似程度

添加了接收用户输入查询的功能，并计算查询与文本块之间的相似度，接着使用langchain库的load_qa_chain函数加载一个预先训练好的问答模型，接上文，代码如下

~~~
from dotenv import load_dotenv
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI

def main():
    load_dotenv()
    st.set_page_config(page_title="Ask your PDF")
    st.title("Ask your PDF")

    pdf = st.file_uploader("Upload your PDF", type="pdf")

    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()

        # split into chunks
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )

        chunks = text_splitter.split_text(text)

        # create embeddings
        embeddings = OpenAIEmbeddings()
        knowledge_base = FAISS.from_texts(chunks, embeddings)

        user_question = st.text_input("Ask your question")
        if user_question:
            docs = knowledge_base.similarity_search(user_question)
            llm = OpenAI()
            chain = load_qa_chain(llm, chain_type="stuff")
            response = chain.run(input_documents=docs, question=user_question)
            st.write(response)
~~~

- `user_question = st.text_input("Ask your question")`：使用`st.text_input`函数在Web页面上创建一个文本输入框，允许用户输入问题。文本输入框的提示文本为“Ask your question”。
- `if user_question:`：使用`if`语句检查用户是否已输入问题。如果用户已输入问题（即`user_question`不为空），则执行以下代码块：
  - `docs = knowledge_base.similarity_search(user_question)`：调用`knowledge_base.similarity_search`方法，计算用户问题与文本块之间的相似度，并将结果存储在`docs`变量中。
  - `response = chain.run(input_documents=docs, question=user_question)`：使用修改后的chain.run方法处理用户输入的问题。输入文档（即与查询相似的文本块）和问题作为参数传递给run方法。
  - `st.write(response)`：将处理后的问答模型的输出显示在页面上。